// Copyright (c) 2023-present Lukas Neubert and contributors (see AUTHORS.md).
// This Source Code is subject to the terms of the Mozilla Public License 2.0.
package tokenizer

import bait.token
import bait.errors

struct Tokenizer {
	path string
	text string
	pos i32
	line i32
	last_nl_pos i32
	is_string_inter bool
	str_quote u8
}

pub fun tokenize(text string, path string) []token.Token {
	mut t := Tokenizer{
		path: path
		text: text
		pos: -1
		line: 1
		last_nl_pos: -1
	}
	mut tokens := []token.Token
	mut tok := token.Token{}
	for tok.kind != token.TokenKind.eof {
		tok = t.next_token()
		tokens.push(tok)
	}
	return tokens
}

fun (t Tokenizer) new_token(kind token.TokenKind, val string) token.Token {
	return token.Token{
		kind: kind
		val: val
		pos: token.Pos{
			line: t.line
			col: t.pos - t.last_nl_pos
		}
	}
}

fun (t Tokenizer) next_token() token.Token {
	for true {
		t.pos += 1
		t.skip_whitespace()
		if t.pos >= t.text.length {
			return t.new_token(token.TokenKind.eof, '')
		}
		c := t.text[t.pos]
		if is_name_start_char(c) {
			return t.name_or_keyword()
		} else if is_digit(c) {
			num := t.number_val()
			return t.new_token(token.TokenKind.number, num)
		}
		nextc := t.text[t.pos + 1]
		match c {
			`'`, `\"` {
				str := t.string_val(c)
				return t.new_token(token.TokenKind.string, str)

			}
			`\`` {
				val := t.char_val()
				return t.new_token(token.TokenKind.char, val)
			}
			`.` {
				return t.new_token(token.TokenKind.dot, "")
			}
			`,` {
				return t.new_token(token.TokenKind.comma, "")
			}
			`+` {
				if nextc == `=`{
					t.pos += 1
					return t.new_token(token.TokenKind.plus_assign, "")
				}
				return t.new_token(token.TokenKind.plus, "")
			}
			`-` {
				if nextc == `=`{
					t.pos += 1
					return t.new_token(token.TokenKind.minus_assign, "")
				}
				return t.new_token(token.TokenKind.minus, "")
			}
			`*` {
				if nextc == `=`{
					t.pos += 1
					return t.new_token(token.TokenKind.mul_assign, "")
				}
				return t.new_token(token.TokenKind.mul, "")
			}
			`/` {
				if nextc == `=`{
					t.pos += 1
					return t.new_token(token.TokenKind.div_assign, "")
				}
				if nextc == `/`{
					t.ignore_line()
					continue
				}
				return t.new_token(token.TokenKind.div, "")
			}
			`%` {
				if nextc == `=`{
					t.pos += 1
					return t.new_token(token.TokenKind.mod_assign, "")
				}
				return t.new_token(token.TokenKind.mod, "")
			}
			`=` {
				if nextc == `=`{
					t.pos += 1
					return t.new_token(token.TokenKind.eq, "")
				}
				return t.new_token(token.TokenKind.assign, "")
			}
			`:` {
				if nextc == `=`{
					t.pos += 1
					return t.new_token(token.TokenKind.decl_assign, "")
				}
				return t.new_token(token.TokenKind.colon, "")
			}
			`;` {
				return t.new_token(token.TokenKind.semicolon, "")
			}
			`!` {
				if nextc == `=`{
					t.pos += 1
					return t.new_token(token.TokenKind.ne, "")
				}
			}
			`<` {
				if nextc == `=`{
					t.pos += 1
					return t.new_token(token.TokenKind.le, "")
				}
				return t.new_token(token.TokenKind.lt, "")
			}
			`>` {
				if nextc == `=`{
					t.pos += 1
					return t.new_token(token.TokenKind.ge, "")
				}
				return t.new_token(token.TokenKind.gt, "")
			}
			`(` {
				return t.new_token(token.TokenKind.lpar, "")
			}
			`)` {
				return t.new_token(token.TokenKind.rpar, "")
			}
			`[` {
				return t.new_token(token.TokenKind.lbr, "")
			}
			`]` {
				return t.new_token(token.TokenKind.rbr, "")
			}
			`{` {
				return t.new_token(token.TokenKind.lcur, "")
			}
			`}` {
				if t.is_string_inter {
					t.is_string_inter = false
					str := t.string_val(t.str_quote)
					return t.new_token(token.TokenKind.string, str)
				}
				return t.new_token(token.TokenKind.rcur, "")
			}
			`|` {
				return t.new_token(token.TokenKind.pipe, "")
			}
			`$` {
				return t.new_token(token.TokenKind.dollar, "")
			}
			`#` {
				t.pos += 1
				name := t.name_val()
				return t.new_token(token.TokenKind.hash, name)
			}
			`@` {
				t.pos += 1
				name := t.name_val()
				return t.new_token(token.TokenKind.attr, name)
			}
			else {}
		}
		t.error('unknown char `${c.ascii()}`')
	}
	return t.new_token(token.TokenKind.eof, "")
}

fun (t Tokenizer) name_or_keyword() token.Token {
	name := t.name_val()
	kind := token.keyword_to_kind(name)
	if kind != token.TokenKind.name {
		return t.new_token(kind, '')
	}
	return t.new_token(token.TokenKind.name, name)
}

fun (t Tokenizer) name_val() string{
	start := t.pos
	t.pos += 1
	for t.pos < t.text.length {
		if not is_name_char(t.text[t.pos]) {
			break
		}
		t.pos += 1
	}
	t.pos -= 1
	return t.text.substr(start, t.pos + 1)
}

fun (t Tokenizer) number_val() string {
	start := t.pos
	for is_digit(t.text[t.pos]) {
		t.pos += 1
	}
	t.pos -= 1
	return t.text.substr(start, t.pos + 1)
}

fun (t Tokenizer) string_val(quote u8) string {
	is_js := t.text[t.pos - 1] == `.`
	start_line := t.line
	start := t.pos + 1
	for true {
		t.pos += 1
		if t.pos >= t.text.length {
			t.error_with_line('unfinished string literal', start_line)
		}
		c := t.text[t.pos]
		if c == `\n` {
			t.last_nl_pos = t.pos
			t.line += 1
		} else if c == `\\` {
			t.pos += 1
		} else if not is_js and c == `$` and t.text[t.pos + 1] == `{` {
			t.is_string_inter = true
			t.str_quote = quote
			t.pos -= 1
			return t.text.substr(start, t.pos + 1)
		} else if c == quote {
			break
		}
	}
	return t.text.substr(start, t.pos)
}

fun (t Tokenizer) char_val() string {
	start := t.pos + 1
	for true {
		t.pos += 1
		c := t.text[t.pos]
		if c == `\\` {
			t.pos += 1
		} else if c == `\`` {
			break
		}
	}
	return t.text.substr(start, t.pos)
}

fun (t Tokenizer) skip_whitespace(){
	for t.pos < t.text.length {
		c := t.text[t.pos]
		if c == `\n` {
			t.last_nl_pos = t.pos
			t.line += 1
		} else if not [` `, `\t`, `\r`].contains(c) {
			return
		}
		t.pos += 1
	}
}

fun (t Tokenizer) ignore_line() {
	for t.pos < t.text.length and t.text[t.pos] != `\n` {
		t.pos += 1
	}
	t.last_nl_pos = t.pos
	t.line += 1
}

fun (t Tokenizer) error(msg string){
	t.error_with_line(msg, t.line)
}

fun (t Tokenizer) error_with_line(msg string, line i32){
	pos := token.Pos{
		line: line
		col: t.pos - t.last_nl_pos
	}
	errors.error(t.path, pos, msg)
	exit(1)
}

fun is_name_start_char(c u8) {
	return c >= `a` and c <= `z` or c >= `A` and c <= `Z` or c == `_`
}

fun is_name_char(c u8) {
	return is_name_start_char(c) or is_digit(c)
}

fun is_digit(c u8) {
	return c >= `0` and c <= `9`
}
