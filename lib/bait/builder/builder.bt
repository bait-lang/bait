// SPDX-FileCopyrightText: 2023-present Lukas Neubert <lukas.neubert@proton.me>
// SPDX-License-Identifier: MPL-2.0
package builder

import os
import bait.ast
import bait.errors
import bait.parser
import bait.checker
import bait.gen.js as jsgen
import bait.gen.c as cgen
import bait.preference
import bait.util.timers

struct Builder {
	table ast.Table
mut:
	prefs preference.Prefs
	parsed_files []ast.File
	checker checker.Checker
}

// Returns the absolute paths to all bait files in a directory that should be compiled
fun (b Builder) collect_bait_files(dir string) []string {
	all_files := os.ls(dir)
	mut files := []string
	for f in all_files {
		if b.prefs.should_compile_file(f) {
			files.push(os.join_path(dir, [f]))
		}
	}
	return files
}

fun (b Builder) get_user_files(path string) []string {
	if os.is_dir(path) {
		return b.collect_bait_files(path)
	}
	if os.exists(path) and path.ends_with('.bt') {
		return [path]
	}
	return []string
}

fun (b Builder) parse_source_file(path string) ast.File {
	text := os.read_file(path)
	return parser.parse(text, path, b.table, b.prefs)
}

pub fun compile(prefs preference.Prefs) i32 {
	mut b := Builder{
		prefs = prefs
		table = ast.new_table()
	}

	// Tokenize and parse all specified files
	timers.start('PARSE')
	mut paths := b.get_user_files(prefs.command)
	mut files := []ast.File
	for p in paths {
		b.prefs.expected_pkg = ''
		files.push(b.parse_source_file(p))
	}

	root_pkg := files[files.length - 1].pkg_decl.full_name

	// Get and parse all imports. Use classic for, as new elements are added to `files`
	for i:=0; i<files.length; i+=1 {
		f := files[i]
		fdir := os.dir(f.path)

		for imp in f.imports {
			if imp.lang != .bait {
				continue
			}

			b.prefs.expected_pkg = imp.name

			// Get all imported files and filter out already parsed ones
			// TODO possible perf improvement: prefilter against list of parsed packages before file collection
			import_dir := resolve_import(fdir, imp.name.replace('.', os.PATH_SEP))
			if not os.exists(import_dir) {
				errors.generic_error('package ${imp.name} not found')
				continue
			}
			mut imp_paths := b.collect_bait_files(import_dir)
			if imp_paths.length == 0 {
				errors.generic_error('package ${imp.name} contains no Bait files')
				continue
			}
			filtered_paths := imp_paths.filter(fun (p string) bool {
				return not paths.contains(p)
			})

			// Parse the imported files
			mut nr_newly_parsed := 0
			for p in filtered_paths {
				parsed_file := b.parse_source_file(p)

				if parsed_file.path.length == 0 {
					continue
				}

				nr_newly_parsed += 1
				paths.push(p)
				files.push(parsed_file)
			}

			if nr_newly_parsed == 0 and filtered_paths.length > 0 {
				errors.generic_error('no files belong to package ${imp.name}')
			}
		}
	}

	timers.show('PARSE')

	b.parsed_files = files
	if b.print_errors_and_warnings(true) {
		return 1
	}

	// TODO move whole depgraph build and resolve into pkg

	timers.start('DEPGRAPH')
	// Build a dependency map for each file
	mut deps := map[string][]string
	for f in files {
		pkg_name := f.pkg_decl.full_name

		for imp in f.imports {
			if imp.lang != .bait {
				continue
			}
			deps[pkg_name].push(imp.name)
		}
	}

	// Sort the packages, so type checking works properly
	mut looked := []string
	mut pkg_order := []string
	order_pkgs(pkg_order, root_pkg, deps, looked)
	mut sorted_files := []ast.File
	for pkg in pkg_order {
		for f in files {
			if f.pkg_decl.full_name == pkg {
				sorted_files.push(f)
			}
		}
	}

	timers.show('DEPGRAPH')

	// Run the type resolver and checker
	timers.start('CHECK')
	b.parsed_files = sorted_files
	b.checker = checker.Checker{
		prefs = b.prefs
		table = b.table
	}
	b.checker.check_files(sorted_files)
	timers.show('CHECK')

	if b.check_redefined_functions() {
		return 1
	}
	if b.print_errors_and_warnings(false) {
		return 1
	}

	if b.prefs.backend == .c {
		return b.code_gen_c()
	}

	return b.code_gen_js()
}

fun (b Builder) code_gen_js() i32 {
	// Run JSGen and write it to the outfile
	timers.start('GEN')
	res := jsgen.gen(b.parsed_files, b.table, b.prefs) + '\n'
	timers.show('GEN')
	ensure_dir_exists(os.dir(b.prefs.out_name))
	os.write_file(b.prefs.out_name, res)

	// Execute the resulting file with NodeJS if required
	if b.prefs.should_run{
		argstr := b.prefs.user_args.join(' ')
		run_res := os.system('node ${b.prefs.out_name} ${argstr}')
		if not b.prefs.keep_exe {
			os.rm(b.prefs.out_name)
		}
		return run_res
	}

	return 0
}

fun (mut b Builder) code_gen_c() i32 {
	timers.start('GEN')
	res := cgen.gen(b.parsed_files, b.table, b.prefs) + '\n'
	timers.show('GEN')

	if os.exists(b.prefs.out_name) and os.is_dir(b.prefs.out_name) {
		b.prefs.out_name += '.exe'
	}
	ensure_dir_exists(os.dir(b.prefs.out_name))

	tmp_c_path := os.join_path(os.tmp_dir(), [os.file_name(b.prefs.out_name) + '.c'])
	os.write_file(tmp_c_path, res)
	comp_res := os.system('cc ${tmp_c_path} -o ${b.prefs.out_name}')
	if comp_res != 0 {
		return comp_res
	}

	if b.prefs.should_run{
		argstr := b.prefs.user_args.join(' ')
		run_res := os.system('./${b.prefs.out_name} ${argstr}')
		if not b.prefs.keep_exe {
			os.rm(b.prefs.out_name)
		}
		return run_res
	}

	return 0
}

fun (b Builder) print_errors_and_warnings(parser_errs bool) bool {
	mut nr_warns := 0
	mut nr_errors := 0

	for f in b.parsed_files {
		nr_warns += f.warnings.length
		nr_errors += f.errors.length

		// -w hides info messages too
		if not b.prefs.hide_warnings {
			for info in f.infos {
				info.print()
			}
		}

		if b.prefs.warn_is_error {
			for warn in f.warnings {
				errors.error(warn.path, warn.pos, warn.msg)
			}
		} else if not b.prefs.hide_warnings {
			for warn in f.warnings {
				warn.print()
			}
		}

		for err in f.errors {
			err.print()
			if parser_errs {
				return true
			}
		}
	}

	nr_errors += b.checker.errors.length
	for err in b.checker.errors {
		err.print()
	}

	return nr_errors > 0 or (b.prefs.warn_is_error and nr_warns > 0)
}

// Resolve an import to absolute file path
fun resolve_import(base_dir string, pkg string) string {
	// Search next to the current file
	mut dir := os.join_path(base_dir, [pkg])
	if os.exists(dir) {
		return dir
	}

	// Search in std lib
	dir = os.resource_abs_path(os.join_path("lib", [pkg]))
	if os.exists(dir) {
		return dir
	}

	// When running make, lib is in the working dir
	return os.join_path(os.getwd(), ["lib", pkg])
}

fun order_pkgs(mut ordered []string, pkg string, deps map[string][]string, mut looked []string) {
	looked.push(pkg)
	for d in deps[pkg] {
		if looked.contains(d) {
			// TODO warn on cyclic deps
			continue
		}
		order_pkgs(ordered, d, deps, looked)
	}
	if not ordered.contains(pkg) {
		ordered.push(pkg)
	}
}

fun ensure_dir_exists(dir string) {
	if not os.exists(dir) {
		os.mkdir(dir)
	}
}
