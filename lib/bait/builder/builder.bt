// SPDX-FileCopyrightText: 2023-present Lukas Neubert <lukas.neubert@proton.me>
// SPDX-License-Identifier: MPL-2.0
package builder

import os
import bait.ast
import bait.errors
import bait.parser
import bait.checker
import bait.gen.js as jsgen
import bait.gen.c as cgen
import bait.preference
import bait.util.timers

struct Builder {
	mut prefs preference.Prefs
	mut parsed_files []ast.File
	mut parsed_pkgs []string
	mut checker checker.Checker
	mut parser parser.Parser
}

// Returns the absolute paths to all bait files in a directory that should be compiled
fun (b Builder) bait_files_in_dir(dir string) []string {
	all_files := os.ls(dir)

	mut files := []string
	for f in all_files {
		if b.should_compile_file(f) {
			files.push(os.join_path(dir, [f]))
		}
	}

	return files
}

fun (b Builder) should_compile_file(file string) bool {
	if not file.ends_with('.bt') {
		return false
	}

	// Exclude test files from compilation
	if file.contains('_test.') {
		return false
	}

	return b.prefs.backend.matches_file(file)
}

fun (b Builder) collect_user_files(path string) []string {
	if os.exists(path) {
		if path.ends_with('.bt') {
			return [path]
		}

		if os.is_dir(path) {
			return b.bait_files_in_dir(path)
		}
	}

	return []string
}

fun (b Builder) parse_file(path string, pkg string) ast.File {
	text := os.read_file(path)
	b.parser.init(text, path, pkg)
	return b.parser.parse()
}

pub fun compile(prefs preference.Prefs) i32 {
	mut b := Builder{
		prefs = prefs
		parser = parser.new(ast.new_table(), prefs)
	}

	// Collect files for compilation
	mut paths := b.collect_user_files(prefs.command)
	if paths.length == 0 {
		errors.generic_error('directory ${prefs.command} contains no Bait files')
		return 1
	}

	// Tokenize and parse files
	timers.start('PARSE')
	mut ast_files := []ast.File
	for p in paths {
		ast_files.push(b.parse_file(p, ''))
	}

	// Resolve and parse imports. New elements are dynamically added to `ast_files`
	for i := 0; i < ast_files.length; i += 1 {
		file := ast_files[i]

		for imp in file.imports {
			if imp.lang != .bait {
				continue
			}

			// Skip already parsed packages
			if b.parsed_pkgs.contains(imp.name) {
				// FIXME possible problem if two imports share the same name but would resolve to different paths
				continue
			}

			// Resolve import path
			import_dir := b.resolve_import(os.dir(file.path), imp.name)
			if not os.exists(import_dir) {
				errors.generic_error('package ${imp.name} not found')
				continue
			}

			// Collect files
			mut imp_paths := b.bait_files_in_dir(import_dir)
			if imp_paths.length == 0 {
				errors.generic_error('package ${imp.name} contains no Bait files')
				continue
			}

			// Parse files
			mut nr_newly_parsed := 0
			for p in imp_paths {
				parsed_file := b.parse_file(p, imp.name)

				if parsed_file.path.length == 0 {
					b.print_infos(parsed_file.infos)
					continue
				}

				nr_newly_parsed += 1
				paths.push(p)
				ast_files.push(parsed_file)
			}

			if nr_newly_parsed == 0 and imp_paths.length > 0 {
				errors.generic_error('no files belong to package ${imp.name}')
			}

			b.parsed_pkgs.push(imp.name)
		}
	}

	timers.show('PARSE')

	b.parsed_files = ast_files
	if b.print_errors_and_warnings(true) {
		return 1
	}

	// TODO move whole depgraph build and resolve into pkg

	timers.start('DEPGRAPH')
	// Build a dependency map for each file
	mut deps := map[string][]string
	for f in ast_files {
		for imp in f.imports {
			if imp.lang != .bait {
				continue
			}
			deps[f.pkg_name].push(imp.name)
		}
	}

	// Sort the packages, so type checking works properly
	mut looked := []string
	mut pkg_order := []string
	order_pkgs(mut pkg_order, ast_files[0].pkg_name, deps, mut looked)
	mut sorted_files := []ast.File
	for pkg in pkg_order {
		for f in ast_files {
			if f.pkg_name == pkg {
				sorted_files.push(f)
			}
		}
	}

	timers.show('DEPGRAPH')

	// Run the type resolver and checker
	timers.start('CHECK')
	b.parsed_files = sorted_files
	b.checker = checker.Checker{
		prefs = b.prefs
		table = b.parser.table
	}
	b.checker.check_files(sorted_files)
	timers.show('CHECK')

	if b.print_errors_and_warnings(false) {
		return 1
	}

	gen_res := b.code_gen()
	if gen_res == 0 {
		return b.run_if_needed()
	}
	return gen_res
}

fun (mut b Builder) code_gen() i32 {
	return match b.prefs.backend {
		.c { b.code_gen_c() }
		.js { b.code_gen_js() }
	}
}

fun (b Builder) code_gen_js() i32 {
	// Run JSGen and write it to the outfile
	timers.start('GEN')
	out_text := jsgen.gen(b.parsed_files, b.parser.table, b.prefs) + '\n'
	timers.show('GEN')
	ensure_dir_exists(os.dir(b.prefs.out_name))
	os.write_file(b.prefs.out_name, out_text)
	return 0
}

fun (mut b Builder) code_gen_c() i32 {
	timers.start('GEN')
	out_text := cgen.gen(b.parsed_files, b.parser.table, b.prefs) + '\n'
	timers.show('GEN')

	if b.prefs.os == .windows {
		b.prefs.out_name += '.exe'
	} else if os.exists_dir(b.prefs.out_name) {
		b.prefs.out_name += '.bin'
	}
	ensure_dir_exists(os.dir(b.prefs.out_name))

	if b.prefs.out_name.ends_with('.c') {
		os.write_file( b.prefs.out_name, out_text)
		return 0
	}

	tmp_c_path := os.join_path(os.tmp_dir(), [os.file_name(b.prefs.out_name) + '.c'])
	os.write_file(tmp_c_path, out_text)
	mut cflags := ''
	if b.prefs.is_library {
		cflags += '-shared -fPIC '
	}
	return os.system('${b.prefs.cc} ${tmp_c_path} ${cflags} -o ${b.prefs.out_name}')
}

fun (b Builder) print_infos(infos []errors.Message) {
	// -w hides info messages too
	if b.prefs.hide_warnings {
		return
	}

	for info in infos {
		info.print()
	}
}

fun (b Builder) print_errors_and_warnings(parser_errs bool) bool {
	mut nr_warns := 0
	mut nr_errors := 0

	for f in b.parsed_files {
		nr_warns += f.warnings.length
		nr_errors += f.errors.length

		b.print_infos(f.infos)

		if b.prefs.warn_is_error {
			for warn in f.warnings {
				errors.error(warn.path, warn.pos, warn.msg)
			}
		} else if not b.prefs.hide_warnings {
			for warn in f.warnings {
				warn.print()
			}
		}

		for err in f.errors {
			err.print()
			if parser_errs {
				return true
			}
		}
	}

	nr_errors += b.checker.errors.length
	for err in b.checker.errors {
		err.print()
	}

	return nr_errors > 0 or (b.prefs.warn_is_error and nr_warns > 0)
}

// Resolve an import to absolute file path
fun (b Builder) resolve_import(base_dir string, name string) string {
	name_as_path := name.replace('.', os.PATH_SEP)

	// Search in std lib
	mut dir := os.resource_abs_path(os.join_path("lib", [name_as_path]))
	if os.exists(dir) {
		return dir
	}

	if b.prefs.is_test {
		// Search in `project_root/src` (next to bait.toml)
		project_root := get_project_root(os.abs_path(base_dir))
		dir = os.join_path(project_root, ['src'])
		if os.exists(dir) {
			return dir
		}

		// Tests next to source code
		return base_dir
	}

	// When running make, lib is in the working dir
	return os.join_path(os.getwd(), ["lib", name_as_path])
}

fun get_project_root(abs_dir string) string {
	if os.is_root(abs_dir) {
		return ''
	}

	files := os.ls(abs_dir)
	if files.contains('bait.toml') {
		return abs_dir
	}

	return get_project_root(os.dir(abs_dir))
}

fun order_pkgs(mut ordered []string, pkg string, deps map[string][]string, mut looked []string) {
	looked.push(pkg)
	for d in deps[pkg] {
		if looked.contains(d) {
			// TODO warn on cyclic deps
			continue
		}
		order_pkgs(mut ordered, d, deps, mut looked)
	}
	if not ordered.contains(pkg) {
		ordered.push(pkg)
	}
}

fun ensure_dir_exists(dir string) {
	if not os.exists(dir) {
		os.mkdir(dir)
	}
}
